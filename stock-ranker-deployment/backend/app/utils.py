# backend/app/utils.py
import pandas as pd
import numpy as np
import yfinance as yf
from ta import add_all_ta_features
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import joblib
import json
from pathlib import Path
from catboost import CatBoostRanker
from typing import List, Tuple, Any

# Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ù…ØµÙ†ÙˆØ¹Ø§Øª (Artifacts)
MODEL_DIR = Path("/app/model_artifacts")
MODEL_PATH = MODEL_DIR / "catboost_ranker_optimized.cbm"
SCALER_PATH = MODEL_DIR / "scaler.pkl"
FEATURES_PATH = MODEL_DIR / "feature_cols.json"
PCA_PATH = MODEL_DIR / "pca.pkl" # Ù…Ø§ Ø§ÛŒÙ† Ø±Ø§ Ù†ÛŒØ² Ø°Ø®ÛŒØ±Ù‡ Ø®ÙˆØ§Ù‡ÛŒÙ… Ú©Ø±Ø¯

# Ù„ÛŒØ³Øª Ù†Ù…Ø§Ø¯Ù‡Ø§ Ø§Ø² Ù†ÙˆØªâ€ŒØ¨ÙˆÚ© Ø´Ù…Ø§
TICKERS = [
    # ğŸ’ Top Tech/Mega-Cap (Ø¨Ø±ØªØ±ÛŒÙ† ÙÙ†Ø§ÙˆØ±ÛŒ Ùˆ Ù…Ú¯Ø§Ú©Ù¾)
    "NVDA", "MSFT", "AAPL", "GOOGL", "GOOG", "AMZN", "META", "TSLA", "AVGO", "ASML",

    # ğŸš€ High Growth & Chipmakers (Ø±Ø´Ø¯ Ø¨Ø§Ù„Ø§ Ùˆ ØªÙˆÙ„ÛŒØ¯Ú©Ù†Ù†Ø¯Ú¯Ø§Ù† ØªØ±Ø§Ø´Ù‡)
    "NFLX", "AMD", "QCOM", "TXN", "AMAT", "INTU", "ADBE", "CRM", "INTC", "MU", 
    "PYPL", "ZM", "OKTA", "SNOW", "PANW", "CDNS", "ANSS", "MRVL", "KLAC", "LRCX",

    # ğŸ›’ Retail & Consumer Staples (Ø®Ø±Ø¯Ù‡â€ŒÙØ±ÙˆØ´ÛŒ Ùˆ Ú©Ø§Ù„Ø§Ù‡Ø§ÛŒ Ø§Ø³Ø§Ø³ÛŒ)
    "COST", "PEP", "WMT", "HD", "MCD", "SBUX", "KO", "PG", "NKE", "TGT", 

    # ğŸ¥ Healthcare & Biotech (Ø¨Ù‡Ø¯Ø§Ø´Øª Ùˆ Ø¯Ø±Ù…Ø§Ù† Ùˆ Ø¨ÛŒÙˆØªÚ©)
    "JNJ", "UNH", "LLY", "ABBV", "PFE", "MRK", "AMGN", "GILD", "BMY", "VRTX",

    # ğŸ’° Financials & Payments (Ù…Ø§Ù„ÛŒ Ùˆ Ù¾Ø±Ø¯Ø§Ø®Øªâ€ŒÙ‡Ø§)
    "JPM", "V", "MA", "BAC", "WFC", "GS", "MS", "AXP", "SPGI", "CME",

    # âš¡ Industrials & Materials (ØµÙ†Ø¹ØªÛŒ Ùˆ Ù…ÙˆØ§Ø¯ Ø§ÙˆÙ„ÛŒÙ‡)
    "LIN", "GE", "CAT", "BA", "MMM", "RTX", "HON", "ECL", "SHW", "DE",

    # ğŸ”‹ Energy & Utilities (Ø§Ù†Ø±Ú˜ÛŒ Ùˆ Ø®Ø¯Ù…Ø§Øª Ø¹Ù…ÙˆÙ…ÛŒ)
    "XOM", "CVX", "EOG", "SLB", "OXY", "COP", "DUK", "NEE", "SO", "AEP",

    # ğŸ  Real Estate & Telecom (Ø§Ù…Ù„Ø§Ú© Ùˆ Ù…Ø³ØªØºÙ„Ø§Øª Ùˆ Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª)
    "T", "VZ", "TMUS", "DLR", "EQIX", "AMT", "CCI", "PLD", "PSA", "URI",

    # âœ¨ Diversified & Others (Ù…ØªÙ†ÙˆØ¹ Ùˆ Ø³Ø§ÛŒØ± Ù…ÙˆØ§Ø±Ø¯)
    "BRK-B", "ORCL", "CMCSA", "DIS", "TMO", "DELL", "MOH", "ISRG", "LOW", "PGR"
]

def load_prediction_tools():
    """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ØŒ scalerØŒ Ù„ÛŒØ³Øª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ùˆ Ù…Ø¯Ù„ PCA"""
    if not all([MODEL_PATH.exists(), SCALER_PATH.exists(), FEATURES_PATH.exists()]):
        raise FileNotFoundError("One or more critical artifacts (model, scaler, features) are missing.")
    
    model = CatBoostRanker()
    model.load_model(str(MODEL_PATH))
    
    scaler = joblib.load(str(SCALER_PATH))
    
    with open(FEATURES_PATH, "r") as f:
        feature_cols = json.load(f)
        
    # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ PCA Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯ØŒ Ø¯Ø± ØºÛŒØ± Ø§ÛŒÙ† ØµÙˆØ±Øª None
    pca = joblib.load(PCA_PATH) if PCA_PATH.exists() else None
        
    return model, scaler, feature_cols, pca

def fetch_raw_data(tickers: List[str]) -> pd.DataFrame:
    """Ø¨Ø®Ø´ Û± Ù†ÙˆØªâ€ŒØ¨ÙˆÚ©: Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ yfinance Ùˆ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù¾Ø§ÛŒÙ‡"""
    print("Step 1: Downloading yfinance historical data...")
    # Ø¨Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ Ù†ÛŒØ§Ø² Ø¯Ø§Ø±ÛŒÙ… (Ù…Ø«Ù„Ø§Ù‹ Û± Ø³Ø§Ù„)
    data = yf.download(tickers, period="1y", group_by="ticker", auto_adjust=False, actions=True)
    
    df = data.stack(level=0, future_stack=True).reset_index().rename(columns={"level_1": "Ticker"})
    df["Date"] = pd.to_datetime(df["Date"])
    df = df.dropna(subset=["Open", "High", "Low", "Close"])
    df = df.drop_duplicates(subset=["Date", "Ticker"])
    df = df.sort_values(by=["Ticker", "Date"])

    print("Step 2: Fetching fundamental info (EPS, Market Cap)...")
    # Ø§ÛŒÙ† Ø¨Ø®Ø´ Ú©Ù†Ø¯ Ø§Ø³ØªØŒ Ø§Ù…Ø§ Ø¨Ø±Ø§ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø´Ù…Ø§ Ø¶Ø±ÙˆØ±ÛŒ Ø§Ø³Øª
    company_info = []
    for ticker in tickers:
        try:
            info = yf.Ticker(ticker).info
            company_info.append({
                "Ticker": ticker,
                "Market Cap": info.get("marketCap"),
                "P/E Ratio": info.get("trailingPE"),
                "EPS": info.get("trailingEps"),
            })
        except Exception:
            company_info.append({"Ticker": ticker}) # Ø§ÙØ²ÙˆØ¯Ù† Ø±Ø¯ÛŒÙ Ø®Ø§Ù„ÛŒ Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§
            
    company_df = pd.DataFrame(company_info)
    df = df.merge(company_df, on="Ticker", how="left")
    
    # Ù¾Ø± Ú©Ø±Ø¯Ù† ffill Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù¾Ø§ÛŒÙ‡ (Ú†ÙˆÙ† Ù‡Ø± Ø±ÙˆØ² ØªØºÛŒÛŒØ± Ù†Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯)
    df[['Market Cap', 'P/E Ratio', 'EPS']] = df.groupby('Ticker')[['Market Cap', 'P/E Ratio', 'EPS']].ffill()

    return df

def run_feature_engineering(df: pd.DataFrame) -> Tuple[pd.DataFrame, PCA]:
    """Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Û³ Ùˆ Û´ Ù†ÙˆØªâ€ŒØ¨ÙˆÚ©: Ø§Ø¬Ø±Ø§ÛŒ Ú©Ø§Ù…Ù„ Ù…Ù‡Ù†Ø¯Ø³ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒ"""
    print("Step 3: Adding Technical Indicators (TA)...")
    # Ù†ÙˆØªâ€ŒØ¨ÙˆÚ© Ø´Ù…Ø§ Ø§Ø² ta Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø±Ø¯Ù‡ Ø§Ø³ØªØŒ Ù†Ù‡ pandas-ta
    df = add_all_ta_features(df, open="Open", high="High", low="Low", close="Close", volume="Volume", fillna=True)

    print("Step 4: Engineering Advanced Features...")
    
    # 4.1. Lag Ù‡Ø§
    for lag in [1, 3, 5]:
        # 'Return_7d' Ù‡Ù†ÙˆØ² ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ØŒ Ù¾Ø³ Ø§Ø² 'Adj Close' Ù„Ú¯ Ù…ÛŒâ€ŒÚ¯ÛŒØ±ÛŒÙ…
        df[f'Adj_Close_Lag_{lag}'] = df.groupby('Ticker')['Adj Close'].shift(lag)
    
    # 4.2. Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†â€ŒÙ‡Ø§ÛŒ Ù…ØªØ­Ø±Ú©
    windows = [5, 10, 20]
    for window in windows:
        df[f'SMA_{window}'] = df.groupby('Ticker')['Adj Close'].rolling(window=window, min_periods=1).mean().reset_index(0, drop=True)
        df[f'EMA_{window}'] = df.groupby('Ticker')['Adj Close'].ewm(span=window, adjust=False, min_periods=1).mean().reset_index(0, drop=True)

    # 4.3. Ù†Ø³Ø¨Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø§Ù„ÛŒ (Ù¾Ø± Ú©Ø±Ø¯Ù† Ù…Ù‚Ø§Ø¯ÛŒØ± 0 Ùˆ NaN)
    df['EPS'] = df['EPS'].replace(0, np.nan).fillna(df.groupby('Ticker')['EPS'].transform('mean')).fillna(0)
    df['Market Cap'] = df['Market Cap'].replace(0, np.nan).fillna(df.groupby('Ticker')['Market Cap'].transform('mean')).fillna(1e-6)
    df['PE_to_EPS'] = df['P/E Ratio'] / (df['EPS'] + 1e-6) # Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² ØªÙ‚Ø³ÛŒÙ… Ø¨Ø± ØµÙØ±

    # 4.4. Ù†ÙˆØ³Ø§Ù†Ø§Øª (Sharpe_Ratio Ø¨Ù‡ Return_7d Ù†ÛŒØ§Ø² Ø¯Ø§Ø±Ø¯ Ú©Ù‡ Ù‡Ù†ÙˆØ² Ù†Ø¯Ø§Ø±ÛŒÙ…)
    df['Volatility_Rolling_Std'] = df.groupby('Ticker')['Adj Close'].rolling(window=10, min_periods=1).std().reset_index(0, drop=True)

    # 4.5. ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø± (Beta, Market_Return)
    df['Market_Return'] = df.groupby('Date')['Adj Close'].transform('mean')
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Beta (Ø³Ø§Ø¯Ù‡ Ø´Ø¯Ù‡)
    cov_matrix = df.groupby('Ticker')[['Adj Close', 'Market_Return']].rolling(window=30).cov().unstack()
    if not cov_matrix.empty:
        beta = cov_matrix[('Adj Close', 'Market_Return')] / (cov_matrix[('Market_Return', 'Market_Return')] + 1e-6)
        df['Beta'] = beta.reset_index(level=0, drop=True)
    else:
        df['Beta'] = 0.0

    # 4.6. PCA (Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø¢Ù†)
    tech_features = [col for col in df.columns if 'momentum_' in col or 'trend_' in col or 'volatility_' in col]
    # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø­Ø°Ù Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ PCA Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨Ù¾Ø°ÛŒØ±Ø¯
    tech_features = [col for col in tech_features if col in df and pd.api.types.is_numeric_dtype(df[col])]
    
    # Ù¾Ø± Ú©Ø±Ø¯Ù† NaN Ù‡Ø§ Ù‚Ø¨Ù„ Ø§Ø² PCA
    df_tech_filled = df[tech_features].fillna(0)
    
    scaler_pca = StandardScaler()
    pca = PCA(n_components=5)
    
    df_tech_scaled = scaler_pca.fit_transform(df_tech_filled)
    pca_features = pca.fit_transform(df_tech_scaled)
    
    for i in range(pca_features.shape[1]):
        df[f'PCA_Tech_{i+1}'] = pca_features[:, i]
        
    # Ø°Ø®ÛŒØ±Ù‡ PCA Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø¹Ø¯ÛŒ (Ø§Ú¯Ø± Ø§ÙˆÙ„ÛŒÙ† Ø¨Ø§Ø± Ø§Ø³Øª)
    if not PCA_PATH.exists():
        joblib.dump(pca, PCA_PATH)

    # 4.7. ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø²Ù…Ø§Ù†ÛŒ
    df['Day_of_Week'] = df['Date'].dt.dayofweek
    df['Month'] = df['Date'].dt.month
    df['Quarter'] = df['Date'].dt.quarter

    print("Step 5: Final data cleanup...")
    # ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¯Ø± Ù†ÙˆØªâ€ŒØ¨ÙˆÚ© Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„ CatBoost Ø­Ø°Ù Ø´Ø¯Ù†Ø¯
    df = df.drop(columns=['Company', 'Sector', 'Industry'], errors='ignore')
    # 'Sentiment' Ø§Ø² Ø§Ø¨ØªØ¯Ø§ Ø§Ø¶Ø§ÙÙ‡ Ù†Ø´Ø¯
    
    # Ø¨Ø§Ø²Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† ÙÙ‚Ø· Ø¢Ø®Ø±ÛŒÙ† Ø±Ø¯ÛŒÙ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù†Ù…Ø§Ø¯
    final_data_today = df.groupby('Ticker').last().reset_index()
    
    return final_data_today, pca
# app/utils.py (Sample)
import json
import os
from typing import List, Dict


def read_recommendations_json(file_path: str) -> List[Dict]:
    """ÙØ§ÛŒÙ„ JSON ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø±Ø§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù†Ø¯."""
    
    # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø­Ø§ØµÙ„ Ú©Ù†ÛŒØ¯ Ú©Ù‡ Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ Ø¯Ø±Ø³Øª Ø§Ø³Øª
    # Ø§ÛŒÙ† Ù…Ø³ÛŒØ± Ø¨Ø§ÛŒØ¯ Ø¨Ù‡ ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ top_k_recommendations.json Ø§Ø´Ø§Ø±Ù‡ Ú©Ù†Ø¯
    
    if not os.path.exists(file_path):
        # Ø§ÛŒÙ† Ø®Ø·Ø§ Ù†Ø¨Ø§ÛŒØ¯ Ø¨Ø§Ø¹Ø« Crash Ø´Ø¯Ù† Ø³Ø±ÙˆØ± Ø´ÙˆØ¯ØŒ Ø¨Ù„Ú©Ù‡ Ø¨Ø§ÛŒØ¯ Ø¯Ø± API Ù…Ø¯ÛŒØ±ÛŒØª Ø´ÙˆØ¯.
        print(f"Warning: Recommendation file not found at {file_path}")
        return []

    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            # ÙØ±Ø¶ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… ÙØ§ÛŒÙ„ JSON ÛŒÚ© Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø§ Ú©Ù„ÛŒØ¯ Ø§ØµÙ„ÛŒ 'top_k_recommendations' Ø§Ø³Øª
            return data.get("top_k_recommendations", [])
    except json.JSONDecodeError:
        print(f"Error: Failed to decode JSON from {file_path}")
        return []
    except Exception as e:
        print(f"An unexpected error occurred while reading JSON: {e}")
        return []